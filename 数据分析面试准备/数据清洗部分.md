# 数据清洗

当我们拿到数据后，一般情况下是无法直接对数据进行分析处理的，应该先对数据进行清洗处理。  

针对数据清洗，有一下几种常见的待清洗数据：缺失值、异常值、重复值。所谓清洗，是对数据集通过丢弃、填充、替换、去重等操作，实现去除异常、纠正错误、补足缺失的目的

## 缺失值

### 1.缺失值如何填补
数据缺失分为两种：  
一是行记录的缺失，这种情况也定义为数据记录丢失；例如对于某一用户，少记录了一项数据
二是数据列值的缺失，指由于各种原因导致的数据记录中某些列的值空缺  

1.丢弃  

这种方法简单明了，直接删除带有缺失值的行记录（整行删除）或者列字段（整列删除），减少缺失数据记录对总体数据的影响。但丢弃意味着会消减数据特征，以下任意一种场景都不宜采用该方法：

1).数据集总体中存在大量的数据记录不完整情况且比例较大，例如超过10%，删除这些带有缺失值的记录意味着将会损失过多有用信息。
2).带有缺失值的数据记录大量存在着明显的数据分布规律或特征，例如带有缺失值的数据记录的目标标签（即分类中的Label变量）主要集中于某一类或几类，如果删除这些数据记录将使对应分类的数据样本丢失大量特征信息，导致模型过拟合或分类不准确。

2.补全

1).统计法：我一般在做数据处理的时候，更偏向于统计法。对于数值型的数据，使用均值、中位数、众数等方法补足；对于分类型数据，使用类别众数最多的值补足。
2).模型法：更多时候我们会基于已有的其他字段，将缺失字段作为目标变量进行预测，从而得到较为可能的补全值。如果带有缺失值的列是数值变量，采用回归模型补全；如果是分类变量，则采用分类模型补全。
3).专家补全：对于少量且具有重要意义的数据记录，专家补足也是非常重要的一种途径。


3.不处理

在数据预处理阶段，对于具有缺失值的数据记录不作任何处理，也是一种思路。这种思路主要看后期的数据分析和建模应用，很多模型对于缺失值有容忍度或灵活的处理方法，因此在预处理阶段可以不做处理。常见的能够自动处理缺失值的模型包括：KNN、决策树和随机森林、神经网络和朴素贝叶斯、DBSCAN（基于密度的带有噪声的空间聚类）等。
这些模型对于缺失值的处理思路是： 
忽略，缺失值不参与距离计算，例如KNN。  
将缺失值作为分布的一种状态，并参与到建模过程，例如各种决策树及其变体。 
不基于距离做计算，因此基于值的距离计算本身的影响就消除了，例如DBSCAN。 


### 2.异常数据如何处理

异常数据，我们也可以叫做离群点，就是原理群体的，不符合主流规律的点。
异常数据是数据分布的常态，处于特定分布区域或范围之外的数据数据通常会被定义为异常或“噪音”。产生数据“噪音”的原因很多，例如业务运营操作、数据采集问题、数据同步问题等。对异常数据进行处理前，需要先辨别出到底哪些是真正的数据异常。

从数据异常的状态看分为两种：
一种是“伪异常”，这些异常是由于业务特定运营动作产生，其实是正常反映业务状态，而不是数据本身的异常规律。  例如双十一超大量订单，就属于伪异常数据  
对于这类异常值，我们时不能剔除的，如果剔除将无法反应真实的业务状态

另一种是“真异常”，这些异常并不是由于特定的业务动作引起，而是客观的反映了数据本身分布异常的分布个案。  
对于这类异常值，我们可以认为是噪声点，需要将其剔除



包容异常值的数据建模

如果数据算法和模型对异常值不敏感，那么即使不处理异常值也不会对模型本身造成负面影响。例如在决策树中，异常值本身就可以作为一种分裂节点。

突然发现决策树很猛... 异常值可以包容，缺失值可以包容，选择XGBOSST就完事了！！
###决策树在分裂点出现缺失值可以分别在左节点和右节点结算损失值，然后选择分裂。异常值可以做one-hot-encoding作为特征节点

### 3.重复数据
数据集中的重复值包括以下两种情况：

1.数据值完全相同的多条数据记录。这是最常见的数据重复情况。  
2.数据主体相同但匹配到的唯一属性值不同。这种情况多见于数据仓库中的变化维度表，同一个事实表的主体会匹配同一个属性的多个值。

一下重复需慎重：
重复的记录用于分析演变规律  
重复的记录用于样本不均衡处理  
重复的记录用于检测业务规则问题  
















